{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/student/2020/cs17m20p100001/miniconda3/envs/NLP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:datasets:PyTorch version 2.3.0 available.\n",
      "INFO:datasets:TensorFlow version 2.16.1 available.\n"
     ]
    }
   ],
   "source": [
    "from entailment_bank.utils.nlp_agent import MultiAngleModel, NlpAgent\n",
    "from llama_entailer import llama_Entailer\n",
    "from entailer import Entailer\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(tree, entailer:Entailer, llama_entailer:llama_Entailer):    \n",
    "    if len(tree.keys()) == 0:\n",
    "        return []\n",
    "    res = []\n",
    "    premises = tree.keys()\n",
    "    for premise in premises:\n",
    "        info = {}\n",
    "        info[\"HYP\"] = premise\n",
    "        info[\"t5_truth\"] = str(entailer.truthfulness_score(premise))\n",
    "        info[\"llama_truth\"] = str(llama_entailer.truthfulness_score(premise))\n",
    "        if len(tree[premise].keys())!=0:\n",
    "            info[\"t5_faith\"] = str(entailer.faithfulness_score(premise, tree[premise].keys()))\n",
    "            info[\"llama_faith\"] = str(llama_entailer.faithfulness_score(premise, tree[premise].keys()))\n",
    "        else:\n",
    "            info[\"t5_faith\"] = str(0.0)\n",
    "            info[\"llama_faith\"] = str(0.0)\n",
    "        \n",
    "        info[\"premises\"] = get_scores(tree[premise], entailer, llama_entailer)\n",
    "        \n",
    "        res.append(info)\n",
    "        \n",
    "    return res\n",
    "\n",
    "def get_score_tree(hyp, entailer:Entailer, llama_entailer:llama_Entailer, prover_prefix=None, depth=3):\n",
    "    info = {}\n",
    "    info[\"HYP\"] = hyp\n",
    "    info[\"t5_truth\"] = str(entailer.truthfulness_score(hyp))\n",
    "    info[\"llama_truth\"] = str(llama_entailer.truthfulness_score(hyp))\n",
    "    if depth==0:\n",
    "        info[\"t5_faith\"] = str(0.0)\n",
    "        info[\"llama_faith\"] = str(0.0)\n",
    "        info[\"premises\"] = []\n",
    "    else:\n",
    "        if prover_prefix is not None:\n",
    "            proof_prefix = \"[PREMISE] \"+prover_prefix\n",
    "            proof = entailer.prover({\"hypothesis\": hyp},  options={\"output_prefix\": {\"proof\": proof_prefix}})\n",
    "        else:\n",
    "            proof = entailer.prover({\"hypothesis\": hyp})\n",
    "        premises = [x.strip() for x in proof.split(\"[PREMISE]\") if x.strip()]\n",
    "        info[\"t5_faith\"] = str(entailer.faithfulness_score(hyp, premises))\n",
    "        info[\"llama_faith\"] = str(llama_entailer.faithfulness_score(hyp, premises))\n",
    "        info[\"premises\"] = []\n",
    "        for premise in premises:\n",
    "            premise_info = get_score_tree(premise, entailer, llama_entailer, prover_prefix=None, depth=depth-1)\n",
    "            info[\"premises\"].append(premise_info)\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.35s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/u/student/2020/cs17m20p100001/miniconda3/envs/NLP/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1583: FutureWarning: `T5ForConditionalGeneration.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'encoder.block.0': 0, 'encoder.block.1': 1, ...}\n",
      "  warnings.warn(\n",
      "/u/student/2020/cs17m20p100001/miniconda3/envs/NLP/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:924: FutureWarning: `T5Stack.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'block.0': 0, 'block.1': 1, ...}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "truth_device = 'cuda:11'\n",
    "info_device =  'cuda:12'\n",
    "\n",
    "info_judge = AutoModelForCausalLM.from_pretrained(\"allenai/truthfulqa-info-judge-llama2-7B\").to(info_device)\n",
    "info_tokenizer = AutoTokenizer.from_pretrained(\"allenai/truthfulqa-info-judge-llama2-7B\", max_length=500)\n",
    "\n",
    "truth_judge = AutoModelForCausalLM.from_pretrained(\"allenai/truthfulqa-truth-judge-llama2-7B\").to(truth_device)\n",
    "truth_tokenizer = AutoTokenizer.from_pretrained(\"allenai/truthfulqa-truth-judge-llama2-7B\", max_length=500)\n",
    "\n",
    "ew_model = MultiAngleModel(model_path=\"allenai/entailer-11b\", cuda_devices=[13, 14])\n",
    "prover = NlpAgent(model=ew_model, default_outputs=\"proof\")\n",
    "entail_verifier = NlpAgent(model=ew_model, default_outputs=[\"implied\"], default_options={\"explicit_outputs\": ['true', 'false']})\n",
    "hyp_verifier = NlpAgent(model=ew_model, default_outputs=[\"valid\"], default_options={\"explicit_outputs\": ['true', 'false']})\n",
    "\n",
    "entailer = Entailer(ew_model, prover, entail_verifier, hyp_verifier)\n",
    "llama_entailer = llama_Entailer(ew_model, prover, entail_verifier, truth_judge, truth_tokenizer, info_judge, info_tokenizer, truth_device, info_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = \"If a moving object slows down, it will have _____ kinetic energy. more\"\n",
    "prover_prefix = \"Anything that is moving has kinetic energy, and the faster it is moving, the more kinetic energy it has.\"\n",
    "\n",
    "tree = get_score_tree(hyp, entailer, llama_entailer, prover_prefix, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HYP': 'If a moving object slows down, it will have _____ kinetic energy. more', 't5_truth': '0.0872523946270124', 'llama_truth': '0.9629448', 't5_faith': '0.5282286909037457', 'llama_faith': '0.9969072377640202', 'premises': [{'HYP': 'Anything that is moving has kinetic energy, and the faster it is moving, the more kinetic energy it has.', 't5_truth': '0.9980767806757831', 'llama_truth': '0.9996535', 't5_faith': '0.9996485765364971', 'llama_faith': '0.6022574278192963', 'premises': [{'HYP': 'Kinetic energy is a measure of the speed at which an object is moving.', 't5_truth': '0.15759111276743043', 'llama_truth': '0.9932254', 't5_faith': '0.99681995379518', 'llama_faith': '0.9462813350065744', 'premises': [{'HYP': 'Kinetic energy is a measure of the speed with which an object is moving.', 't5_truth': '0.16663328878398564', 'llama_truth': '0.9953239', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'Speed is a kind of measure of kinetic energy.', 't5_truth': '0.9049609796656751', 'llama_truth': '0.6892292', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}, {'HYP': 'The faster an object is moving, the more kinetic energy it has.', 't5_truth': '0.997553705214975', 'llama_truth': '0.99803364', 't5_faith': '0.9996742063525066', 'llama_faith': '0.8175870589300729', 'premises': [{'HYP': 'Kinetic energy is a measure of how fast an object is moving.', 't5_truth': '0.6872676355906199', 'llama_truth': '0.9982903', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'The faster an object is moving, the more kinetic energy it has.', 't5_truth': '0.997553705214975', 'llama_truth': '0.99803364', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}]}, {'HYP': 'If an object is moving slower then it will have less kinetic energy.', 't5_truth': '0.9891801263337637', 'llama_truth': '0.99408793', 't5_faith': '0.9941877067191484', 'llama_faith': '0.027600009615508014', 'premises': [{'HYP': 'If an object is moving slower then it will have less momentum.', 't5_truth': '0.9567889229439062', 'llama_truth': '0.98907393', 't5_faith': '0.9991796774973873', 'llama_faith': '0.8707486217781693', 'premises': [{'HYP': 'If an object is moving slower then it will be moving slower.', 't5_truth': '0.9918465642058838', 'llama_truth': '0.99907637', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'If an object is moving slower then it will have less momentum.', 't5_truth': '0.9567889229439062', 'llama_truth': '0.98907393', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}, {'HYP': 'Kinetic energy is the measure of the amount of energy an object has.', 't5_truth': '0.9005729303559559', 'llama_truth': '0.99740607', 't5_faith': '0.9864320584171538', 'llama_faith': '0.9033904898658989', 'premises': [{'HYP': 'Energy is a measure of the amount of force an object has.', 't5_truth': '0.6877055729187735', 'llama_truth': '0.8430891', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'Kinetic energy is the force an object has.', 't5_truth': '0.0042806874666940775', 'llama_truth': '0.97240245', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"allenai/quartz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/784 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 784/784 [10:18:03<00:00, 47.30s/it] \n"
     ]
    }
   ],
   "source": [
    "with open('fulldepth_quartz_scores.jsonl', 'a') as f:\n",
    "    for i in tqdm(range(len(dataset['test']))):\n",
    "        data = dataset[\"test\"][i]\n",
    "        for j in range(len(data[\"choices\"][\"text\"])):\n",
    "            hyp = data[\"question\"]+\" \"+data[\"choices\"]['text'][j]\n",
    "            prover_prefix = data[\"para\"]\n",
    "            \n",
    "            tree = get_score_tree(hyp, entailer, llama_entailer, prover_prefix, 3)\n",
    "            \n",
    "            json.dump(tree, f)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"truthful_qa\", 'multiple_choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [13:51:49<00:00, 61.09s/it]  \n"
     ]
    }
   ],
   "source": [
    "with open('fulldepth_truthfulqa_scores.jsonl', 'a') as f:\n",
    "    for i in tqdm(range(len(dataset['validation']))):\n",
    "        data = dataset[\"validation\"][i]\n",
    "        for j in range(min(3, len(data[\"mc1_targets\"][\"choices\"]))):\n",
    "            hyp = data[\"question\"]+\" \"+data[\"mc1_targets\"][\"choices\"][j]\n",
    "            \n",
    "            tree = get_score_tree(hyp, entailer, llama_entailer, prover_prefix=None, depth=3)\n",
    "            \n",
    "            json.dump(tree, f)\n",
    "            f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
