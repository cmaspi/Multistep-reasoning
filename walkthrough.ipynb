{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/student/2020/cs17m20p100001/miniconda3/envs/NLP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:datasets:PyTorch version 2.3.0 available.\n",
      "INFO:datasets:TensorFlow version 2.16.1 available.\n"
     ]
    }
   ],
   "source": [
    "from entailment_bank.utils.nlp_agent import MultiAngleModel, NlpAgent\n",
    "from llama_entailer import llama_Entailer\n",
    "from entailer import Entailer\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from truth_faith_score import get_score_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating full-depth score tree using t5 and llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/u/student/2020/cs17m20p100001/miniconda3/envs/NLP/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1583: FutureWarning: `T5ForConditionalGeneration.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'encoder.block.0': 0, 'encoder.block.1': 1, ...}\n",
      "  warnings.warn(\n",
      "/u/student/2020/cs17m20p100001/miniconda3/envs/NLP/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:924: FutureWarning: `T5Stack.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'block.0': 0, 'block.1': 1, ...}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "truth_device = 'cuda:11'\n",
    "info_device =  'cuda:12'\n",
    "\n",
    "info_judge = AutoModelForCausalLM.from_pretrained(\"allenai/truthfulqa-info-judge-llama2-7B\").to(info_device)\n",
    "info_tokenizer = AutoTokenizer.from_pretrained(\"allenai/truthfulqa-info-judge-llama2-7B\", max_length=500)\n",
    "\n",
    "truth_judge = AutoModelForCausalLM.from_pretrained(\"allenai/truthfulqa-truth-judge-llama2-7B\").to(truth_device)\n",
    "truth_tokenizer = AutoTokenizer.from_pretrained(\"allenai/truthfulqa-truth-judge-llama2-7B\", max_length=500)\n",
    "\n",
    "ew_model = MultiAngleModel(model_path=\"allenai/entailer-11b\", cuda_devices=[13, 14])\n",
    "prover = NlpAgent(model=ew_model, default_outputs=\"proof\")\n",
    "entail_verifier = NlpAgent(model=ew_model, default_outputs=[\"implied\"], default_options={\"explicit_outputs\": ['true', 'false']})\n",
    "hyp_verifier = NlpAgent(model=ew_model, default_outputs=[\"valid\"], default_options={\"explicit_outputs\": ['true', 'false']})\n",
    "\n",
    "entailer = Entailer(ew_model, prover, entail_verifier, hyp_verifier)\n",
    "llama_entailer = llama_Entailer(ew_model, prover, entail_verifier, truth_judge, truth_tokenizer, info_judge, info_tokenizer, truth_device, info_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = \"Rich has a leaf with a small surface area. This adaptation likely causes less water vapor to evaporate\"\n",
    "\n",
    "tree = get_score_tree(hyp, entailer, llama_entailer, prover_prefix=None, depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HYP': 'Rich has a leaf with a small surface area. This adaptation likely causes less water vapor to evaporate', 't5_truth': '0.15019136867302618', 'llama_truth': '0.99533564', 't5_faith': '0.9219023463676145', 'llama_faith': '0.9994847355224437', 'premises': [{'HYP': 'A leaf with a small surface area will absorb less water vapor.', 't5_truth': '0.7671776399277875', 'llama_truth': '0.9975401', 't5_faith': '0.9966529393501569', 'llama_faith': '0.8766601781165875', 'premises': [{'HYP': 'As the surface area of a leaf decreases, the amount of water vapor absorbed by that leaf will decrease.', 't5_truth': '0.808694537717028', 'llama_truth': '0.9893165', 't5_faith': '0.9946293803544977', 'llama_faith': '3.344236080934953e-07', 'premises': [{'HYP': 'As the surface area of a substance decreases, the amount of that substance absorbed by that object will decrease.', 't5_truth': '0.784831773963933', 'llama_truth': '0.9945073', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'A leaf is a kind of object.', 't5_truth': '0.9992756969322972', 'llama_truth': '0.9885877', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'Water vapor is a kind of substance.', 't5_truth': '0.9951568524421008', 'llama_truth': '0.9864528', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}, {'HYP': 'If the amount of water vapor absorbed by a leaf decreases then that leaf will absorb less water vapor.', 't5_truth': '0.9054090829650346', 'llama_truth': '0.9897351', 't5_faith': '0.9978558222960177', 'llama_faith': '0.0009154211537492074', 'premises': [{'HYP': 'If something decreases then that something will absorb less of that something.', 't5_truth': '0.6331750521035939', 'llama_truth': '0.9838', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'The amount of water vapor absorbed by a leaf is a kind of thing.', 't5_truth': '0.985232914707965', 'llama_truth': '0.9976155', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}]}, {'HYP': 'If an organism absorbs less water vapor then that organism will likely have less water vapor to evaporate.', 't5_truth': '0.6275567189776534', 'llama_truth': '0.9924017', 't5_faith': '0.9964851327732313', 'llama_faith': '0.0006568534479924892', 'premises': [{'HYP': 'If a living thing absorbs less water vapor then that living thing will likely have less water vapor to evaporate.', 't5_truth': '0.6178483008716803', 'llama_truth': '0.9950951', 't5_faith': '0.8920520397324214', 'llama_faith': '0.9914465904815728', 'premises': [{'HYP': 'If a living thing absorbs less water vapor then that living thing will likely have less water vapor to absorb.', 't5_truth': '0.4840572006782269', 'llama_truth': '0.9982152', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'If something absorbs something else then that something will likely have less of that something else to absorb.', 't5_truth': '0.5610536681457372', 'llama_truth': '0.99935657', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}, {'HYP': 'An organism is a kind of living thing.', 't5_truth': '0.9995737802187696', 'llama_truth': '0.99749017', 't5_faith': '0.999825123947727', 'llama_faith': '0.8046115482516143', 'premises': [{'HYP': 'An organism is a kind of living thing.', 't5_truth': '0.9995737802187696', 'llama_truth': '0.99749017', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'Organisms are a kind of living thing.', 't5_truth': '0.9995056558376533', 'llama_truth': '0.9948509', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the truth scores using llama-7b that is pre-trained on truthfulqa\n",
    "\n",
    "Dataset used for training can be found at `truthfulqa_reeval/data/ARC+world_tree.jsonl`\n",
    "\n",
    "Finetuning script can be found at `truthfulqa_reeval/scripts/finetune_judge.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "finetuned_truth_judge = AutoModelForCausalLM.from_pretrained(\"truthfulqa_reeval/output/llama2_7B_truth_judge_final\").to('cuda:15')\n",
    "finetuned_truth_tokenizer = AutoTokenizer.from_pretrained(\"truthfulqa_reeval/output/llama2_7B_truth_judge_final\", max_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modify_scores import modify_truth_scores\n",
    "\n",
    "modified_tree = modify_truth_scores(tree, finetuned_truth_judge, finetuned_truth_tokenizer, 'cuda:15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HYP': 'Rich has a leaf with a small surface area. This adaptation likely causes less water vapor to evaporate', 't5_truth': '0.15019136867302618', 'llama_truth': '0.5601153', 't5_faith': '0.9219023463676145', 'llama_faith': '0.9994847355224437', 'premises': [{'HYP': 'A leaf with a small surface area will absorb less water vapor.', 't5_truth': '0.7671776399277875', 'llama_truth': '0.91927266', 't5_faith': '0.9966529393501569', 'llama_faith': '0.8766601781165875', 'premises': [{'HYP': 'As the surface area of a leaf decreases, the amount of water vapor absorbed by that leaf will decrease.', 't5_truth': '0.808694537717028', 'llama_truth': '0.8495511', 't5_faith': '0.9946293803544977', 'llama_faith': '3.344236080934953e-07', 'premises': [{'HYP': 'As the surface area of a substance decreases, the amount of that substance absorbed by that object will decrease.', 't5_truth': '0.784831773963933', 'llama_truth': '0.9945073', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'A leaf is a kind of object.', 't5_truth': '0.9992756969322972', 'llama_truth': '0.9885877', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'Water vapor is a kind of substance.', 't5_truth': '0.9951568524421008', 'llama_truth': '0.9864528', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}, {'HYP': 'If the amount of water vapor absorbed by a leaf decreases then that leaf will absorb less water vapor.', 't5_truth': '0.9054090829650346', 'llama_truth': '0.9126174', 't5_faith': '0.9978558222960177', 'llama_faith': '0.0009154211537492074', 'premises': [{'HYP': 'If something decreases then that something will absorb less of that something.', 't5_truth': '0.6331750521035939', 'llama_truth': '0.9838', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'The amount of water vapor absorbed by a leaf is a kind of thing.', 't5_truth': '0.985232914707965', 'llama_truth': '0.9976155', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}]}, {'HYP': 'If an organism absorbs less water vapor then that organism will likely have less water vapor to evaporate.', 't5_truth': '0.6275567189776534', 'llama_truth': '0.77339816', 't5_faith': '0.9964851327732313', 'llama_faith': '0.0006568534479924892', 'premises': [{'HYP': 'If a living thing absorbs less water vapor then that living thing will likely have less water vapor to evaporate.', 't5_truth': '0.6178483008716803', 'llama_truth': '0.8866345', 't5_faith': '0.8920520397324214', 'llama_faith': '0.9914465904815728', 'premises': [{'HYP': 'If a living thing absorbs less water vapor then that living thing will likely have less water vapor to absorb.', 't5_truth': '0.4840572006782269', 'llama_truth': '0.9982152', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'If something absorbs something else then that something will likely have less of that something else to absorb.', 't5_truth': '0.5610536681457372', 'llama_truth': '0.99935657', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}, {'HYP': 'An organism is a kind of living thing.', 't5_truth': '0.9995737802187696', 'llama_truth': '0.99888754', 't5_faith': '0.999825123947727', 'llama_faith': '0.8046115482516143', 'premises': [{'HYP': 'An organism is a kind of living thing.', 't5_truth': '0.9995737802187696', 'llama_truth': '0.99749017', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}, {'HYP': 'Organisms are a kind of living thing.', 't5_truth': '0.9995056558376533', 'llama_truth': '0.9948509', 't5_faith': '0.0', 'llama_faith': '0.0', 'premises': []}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "print(modified_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
