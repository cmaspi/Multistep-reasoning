{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('obqa.parquet', engine='pyarrow')\n",
    "answers = df['answerKey'].map(\n",
    "    {'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3}\n",
    ").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A person wants to start saving money so that they can afford a nice vacation at the end of the year. After looking over their budget and expenses, they decide the best way to save money is to'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question_stem'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['HYP', 't5_truth', 'llama_truth', 't5_faith', 'llama_faith', 'premises'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../results/fulldepth_obqa_scores_finetuned.jsonl'\n",
    "\n",
    "import json\n",
    "with open(file_path, 'r') as f:\n",
    "    f.readline()\n",
    "    f.readline()\n",
    "    f.readline()\n",
    "    line = f.readline().strip()\n",
    "    d = json.loads(line)\n",
    "\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A person wants to start saving money so that they can afford a nice vacation at the end of the year. After looking over their budget and expenses, they decide the best way to save money is to have lunch with friends'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['HYP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HYP': 'A person wants to start saving money for a vacation at the end of the year.',\n",
       " 't5_truth': '0.9157349103157619',\n",
       " 'llama_truth': '0.4754670262336731',\n",
       " 't5_faith': '0.8787753636560861',\n",
       " 'llama_faith': '0.3538497759241288',\n",
       " 'premises': [{'HYP': 'A person wants to start saving money for a vacation.',\n",
       "   't5_truth': '0.9726121919390229',\n",
       "   'llama_truth': '0.94086844',\n",
       "   't5_faith': '0.0',\n",
       "   'llama_faith': '0.0',\n",
       "   'premises': []},\n",
       "  {'HYP': 'The end of the year is when most people take vacations.',\n",
       "   't5_truth': '0.2421582384858808',\n",
       "   'llama_truth': '0.2950717806816101',\n",
       "   't5_faith': '0.0',\n",
       "   'llama_faith': '0.0',\n",
       "   'premises': []}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['premises'][0]['premises'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cummul(a):\n",
    "    \"\"\"cumulative multiplication\"\"\"\n",
    "    res = 1\n",
    "    for i in a:\n",
    "        res *= i\n",
    "    return res\n",
    "\n",
    "\n",
    "def reasoning_score(t: List, e: float, mode):\n",
    "    if mode == 'm':\n",
    "        return cummul(t) * e\n",
    "    elif mode == 'gmt':\n",
    "        return math.pow(cummul(t), 1 / len(t)) * e\n",
    "    else:\n",
    "        return math.pow(cummul(t) * e, 1 / (1 + len(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = {\n",
    "'ttm': \"t5-truthfulness, t5-faithfullness, all direct multiplication\",\n",
    "'ttgmt': \"t5-truthfulness, t5-faithfullness, faithfullness * gm of truthfullness\",\n",
    "'ttgm': \"t5-truthfulness, t5-faithfullness, gm of both truthfulness and faithfulness\",\n",
    "'ltm': \"llama-truthfulness, t5-faithfullness, all direct multiplication\",\n",
    "'ltgmt': \"llama-truthfulness, t5-faithfullness, faithfullness * gm of truthfullness\",\n",
    "'ltgm': \"llama-truthfulness, t5-faithfullness, gm of both truthfulness and faithfulness\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttvals, ltvals, tfvals, lfvals = [], [], [], [] \n",
    "\n",
    "def extract_values(d):\n",
    "    tt = float(d['t5_truth'])\n",
    "    lt = float(d['llama_truth'])\n",
    "    tf = float(d['t5_faith'])\n",
    "    lf = float(d['llama_faith'])\n",
    "    ttvals.append(tt)\n",
    "    ltvals.append(lt)\n",
    "    if d['premises']:\n",
    "        tfvals.append(tf)\n",
    "        lfvals.append(lf)\n",
    "        for p in d['premises']:\n",
    "            extract_values(p)\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        d = json.loads(line.strip())\n",
    "        extract_values(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30441,), (30441,), (14232,), (14232,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttvals, ltvals, tfvals, lfvals = np.array(ttvals), np.array(ltvals), np.array(tfvals), np.array(lfvals)\n",
    "\n",
    "ttvals.shape, ltvals.shape, tfvals.shape, lfvals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_inv(x):\n",
    "    return np.log(x / (1 - x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / ( 1 + np.exp(-x))\n",
    "\n",
    "logits_tt = sig_inv(ttvals)\n",
    "logits_tf = sig_inv(tfvals)\n",
    "logits_lt = sig_inv(ltvals)\n",
    "logits_lf = sig_inv(lfvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "class lin_transform:\n",
    "    def fit(self, x, y):\n",
    "        def objective(params, arr1, arr2):\n",
    "            a, b = params\n",
    "            transformed_arr1 = a * arr1 + b\n",
    "            return np.sum((transformed_arr1 - arr2)**2)\n",
    "\n",
    "        # Initial guess for a and b\n",
    "        initial_guess = [1, 0]\n",
    "\n",
    "        # Optimization\n",
    "        result = minimize(objective, initial_guess, args=(x, y))\n",
    "\n",
    "        # Extract optimized constants\n",
    "        self.a, self.b = result.x\n",
    "\n",
    "    def transform(self, x):\n",
    "        # return x\n",
    "        return self.a * x + self.b\n",
    "\n",
    "\n",
    "transform_t = lin_transform()\n",
    "transform_t.fit(logits_lt, logits_tt)\n",
    "transform_f = lin_transform()\n",
    "transform_f.fit(logits_lf, logits_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8533741243931974 1.741459361583275\n"
     ]
    }
   ],
   "source": [
    "print(transform_t.a, transform_t.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.633535919425435, 3.633535879180158)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_t.transform(logits_lt).mean(), logits_tt.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entailer + Direct\n",
    "\n",
    "def get_scores(d, mode, depth):\n",
    "    def direct_score(d, mode):\n",
    "        if mode[0] == 't': # t5\n",
    "            score = float(d['t5_truth'])\n",
    "        else:\n",
    "            score = float(d['llama_truth'])\n",
    "            logit = sig_inv(score)\n",
    "            transformed_logit = transform_t.transform(logit)\n",
    "            score = sigmoid(transformed_logit)\n",
    "        return score\n",
    "\n",
    "    def entailment_score(d, mode):\n",
    "        if mode[1] == 't':\n",
    "            entail_score = float(d['t5_faith'])\n",
    "        else:\n",
    "            entail_score = float(d['llama_faith'])\n",
    "            logit = sig_inv(entail_score)\n",
    "            transformed_logit = transform_f.transform(logit)\n",
    "            entail_score = sigmoid(transformed_logit)\n",
    "        return float(entail_score)\n",
    "\n",
    "\n",
    "    sd = direct_score(d, mode)\n",
    "    if depth == 0:\n",
    "        return sd\n",
    "    cd = max(sd, 1-sd)\n",
    "    se = entailment_score(d, mode)\n",
    "\n",
    "    if se > cd:\n",
    "        p_scores = [get_scores(p, mode, depth-1) for p in d['premises']]\n",
    "        sr = reasoning_score(p_scores, se, mode[2:])\n",
    "    else:\n",
    "        sr = 0\n",
    "    return max(sr, sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entailer\n",
    "\n",
    "def get_scores(d, mode, depth):\n",
    "    def direct_score(d, mode):\n",
    "        if mode[0] == 't': # t5\n",
    "            score = float(d['t5_truth'])\n",
    "        else:\n",
    "            score = float(d['llama_truth'])\n",
    "            logit = sig_inv(score)\n",
    "            transformed_logit = transform_t.transform(logit)\n",
    "            score = sigmoid(transformed_logit)\n",
    "        return score\n",
    "\n",
    "    def entailment_score(d, mode):\n",
    "        if mode[1] == 't':\n",
    "            entail_score = float(d['t5_faith'])\n",
    "        else:\n",
    "            entail_score = float(d['llama_faith'])\n",
    "            logit = sig_inv(entail_score)\n",
    "            transformed_logit = transform_f.transform(logit)\n",
    "            entail_score = sigmoid(transformed_logit)\n",
    "        return entail_score\n",
    "\n",
    "\n",
    "    sd = direct_score(d, mode)\n",
    "    if depth == 0:\n",
    "        return sd\n",
    "    se = entailment_score(d, mode)\n",
    "\n",
    "    p_scores = [get_scores(p, mode, depth-1) for p in d['premises']]\n",
    "    sr = reasoning_score(p_scores, se, mode[2:])\n",
    "    return sr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entailer + direct: Root with T5, rest with llama for truth\n",
    "\n",
    "def get_scores(d, mode, depth, use_t5=True):\n",
    "    def direct_score(d, mode):\n",
    "        if use_t5:\n",
    "            score = float(d['t5_truth'])\n",
    "        else:\n",
    "            score = float(d['llama_truth'])\n",
    "            logit = sig_inv(score)\n",
    "            transformed_logit = transform_t.transform(logit)\n",
    "            score = sigmoid(transformed_logit)\n",
    "        return score\n",
    "\n",
    "    def entailment_score(d, mode):\n",
    "        entail_score = float(d['t5_faith'])\n",
    "        return entail_score\n",
    "\n",
    "\n",
    "    sd = direct_score(d, mode)\n",
    "    if depth == 0:\n",
    "        return sd\n",
    "    cd = max(sd, 1-sd)\n",
    "    se = entailment_score(d, mode)\n",
    "\n",
    "    if se > cd:\n",
    "        p_scores = [get_scores(p, mode, depth-1, False) for p in d['premises']]\n",
    "        sr = reasoning_score(p_scores, se, mode[2:])\n",
    "    else:\n",
    "        sr = 0\n",
    "    return max(sr, sd)\n",
    "\n",
    "\n",
    "modes = ['_tm', '_tgmt', '_tgm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$$$$$$\n",
      "0\n",
      "ttm: 0.74\n",
      "ttgmt: 0.74\n",
      "ttgm: 0.74\n",
      "ltm: 0.618\n",
      "ltgmt: 0.618\n",
      "ltgm: 0.618\n",
      "$$$$$$$$$$\n",
      "1\n",
      "ttm: 0.63\n",
      "ttgmt: 0.65\n",
      "ttgm: 0.628\n",
      "ltm: 0.612\n",
      "ltgmt: 0.658\n",
      "ltgm: 0.62\n",
      "$$$$$$$$$$\n",
      "2\n",
      "ttm: 0.538\n",
      "ttgmt: 0.608\n",
      "ttgm: 0.596\n",
      "ltm: 0.552\n",
      "ltgmt: 0.622\n",
      "ltgm: 0.604\n",
      "$$$$$$$$$$\n",
      "3\n",
      "ttm: 0.492\n",
      "ttgmt: 0.61\n",
      "ttgm: 0.614\n",
      "ltm: 0.57\n",
      "ltgmt: 0.658\n",
      "ltgm: 0.666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for depth in range(4):\n",
    "    print('$'*10)\n",
    "    print(depth)\n",
    "    for mode in modes:\n",
    "        pred_ans = []\n",
    "        print(mode, end=': ')\n",
    "        with open(file_path, 'r') as f:\n",
    "            dicts = []\n",
    "            for line in f:\n",
    "                d = json.loads(line.strip())\n",
    "                dicts.append(d)\n",
    "                \n",
    "                if len(dicts) >= 4:\n",
    "                    scores = [get_scores(d, mode, depth) for d in dicts]\n",
    "                    pred_ans.append(np.argmax(scores))     \n",
    "                    dicts = []\n",
    "                    \n",
    "        print(accuracy_score(answers, pred_ans))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multistep-reasoning-hBGzQBr9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
